- The computational complexity or just simply complexity of an algorithm is the amount of resources required to run it, especially with respect to time and memory requirements.
    - How much time does an algorithm need to finish?
    - How much space does an algorithm need for its computation?
- [[Big-O]] gives an asymptotic upper bound of the growth rate in the worst case, which helps to quantify algorithmic performance as input size grows infinitely.
- It describes how the time and space requirements of an algorithm increase as its input size grows.

- The three most important things when it comes to studying the performance of data structures:
    - **Correctness** - correct implementation of interface.
    - **[[Time Complexity]]** - The running times of operations should be as small as possible.
    - **[[Space Complexity]]** - Memory use should be as little as possible.

- Things that cause time in a function:
    - Arithmetic operations
    - Comparisons
    - Loops
    - Outside function calls
- Things that cause space complexity:
    - Variables
    - Function calls
    - Allocations
    - Data structures

---

- [[Time Complexity]]
    - Cost Model
    - Order of Growth
    - [[Big-O]]
- [[Space Complexity]]
- NP Completeness
- Amortization

## Further

### Reads ðŸ“„

- [[Math]]
